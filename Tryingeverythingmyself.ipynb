{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import zh_core_web_sm\n",
    "import  pkuseg\n",
    "import jieba\n",
    "import jieba.posseg\n",
    "import pycantonese as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynlpir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.811 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "nlp = zh_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as re\n",
    "from math import sqrt\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'All.xlsx')\n",
    "df = pd.DataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfchinese = pd.DataFrame(columns=['Text'])\n",
    "for i in range(len(df)):\n",
    "    x = re.sub(\"[a-z]|[0-9]|M\",\"\", df['Text'].iloc[i])\n",
    "    y = re.sub(\"/\",\"\", x)\n",
    "    z = re.sub(\" \",\"\", y)\n",
    "    dfchinese = dfchinese.append({'Text': z}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What sentence we will analyse \n",
      " 每天早上，媽媽都會為我準備早餐，並且送我到學校。然後，她就去運動場跑步。放學後，當我做功課時，有不明白的地方，媽媽便像老師一樣，坐到我身邊，循循善誘地指導我，令我茅塞頓開。\n"
     ]
    }
   ],
   "source": [
    "print('What sentence we will analyse','\\n', dfchinese['Text'].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['每天',\n",
       " '早上',\n",
       " '，',\n",
       " '媽媽',\n",
       " '都',\n",
       " '會為',\n",
       " '我',\n",
       " '準備',\n",
       " '早餐',\n",
       " '，',\n",
       " '並且',\n",
       " '送',\n",
       " '我',\n",
       " '到',\n",
       " '學校',\n",
       " '。',\n",
       " '然後',\n",
       " '，',\n",
       " '她',\n",
       " '就',\n",
       " '去',\n",
       " '運動場',\n",
       " '跑步',\n",
       " '。',\n",
       " '放學',\n",
       " '後',\n",
       " '，',\n",
       " '當',\n",
       " '我',\n",
       " '做',\n",
       " '功課時',\n",
       " '，',\n",
       " '有',\n",
       " '不',\n",
       " '明白',\n",
       " '的',\n",
       " '地方',\n",
       " '，',\n",
       " '媽媽',\n",
       " '便',\n",
       " '像',\n",
       " '老師',\n",
       " '一',\n",
       " '樣',\n",
       " '，',\n",
       " '坐到',\n",
       " '我',\n",
       " '身邊',\n",
       " '，',\n",
       " '循循善誘',\n",
       " '地',\n",
       " '指導',\n",
       " '我',\n",
       " '，',\n",
       " '令',\n",
       " '我',\n",
       " '茅塞',\n",
       " '頓開',\n",
       " '。']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pkuseg segmentation but no PoS\n",
    "seg  =  pkuseg.pkuseg () \n",
    "a = dfchinese['Text'].iloc[2]\n",
    "text  =  seg.cut(a)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['每天 r',\n",
       " '早上 t',\n",
       " '， x',\n",
       " '媽媽 n',\n",
       " '都 d',\n",
       " '會 v',\n",
       " '為 p',\n",
       " '我 r',\n",
       " '準備 v',\n",
       " '早餐 n',\n",
       " '， x',\n",
       " '並且 c',\n",
       " '送 v',\n",
       " '我 r',\n",
       " '到 v',\n",
       " '學校 n',\n",
       " '。 x',\n",
       " '然 r',\n",
       " '後 nr',\n",
       " '， x',\n",
       " '她 r',\n",
       " '就 d',\n",
       " '去 v',\n",
       " '運動場 n',\n",
       " '跑步 n',\n",
       " '。 x',\n",
       " '放學 n',\n",
       " '後 nr',\n",
       " '， x',\n",
       " '當 p',\n",
       " '我 r',\n",
       " '做功 v',\n",
       " '課時 t',\n",
       " '， x',\n",
       " '有 v',\n",
       " '不 d',\n",
       " '明白 nr',\n",
       " '的 uj',\n",
       " '地方 n',\n",
       " '， x',\n",
       " '媽媽 n',\n",
       " '便 d',\n",
       " '像 v',\n",
       " '老師 n',\n",
       " '一樣 u',\n",
       " '， x',\n",
       " '坐到 v',\n",
       " '我 r',\n",
       " '身邊 s',\n",
       " '， x',\n",
       " '循循善誘 i',\n",
       " '地 uv',\n",
       " '指導 v',\n",
       " '我 r',\n",
       " '， x',\n",
       " '令 v',\n",
       " '我 r',\n",
       " '茅塞 nr',\n",
       " '頓 q',\n",
       " '開 v',\n",
       " '。 x']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#JIEBA\n",
    "\n",
    "words = jieba.posseg.cut(a)\n",
    "c=[]\n",
    "for word, flag in words:\n",
    "    c.append('%s %s' % (word, flag))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每天 ADV\n",
      "早上 NOUN\n",
      "， PUNCT\n",
      "媽媽 NOUN\n",
      "都 ADV\n",
      "會為 VERB\n",
      "我 PRON\n",
      "準備 NOUN\n",
      "早餐 ADV\n",
      "， PUNCT\n",
      "並且 VERB\n",
      "送 VERB\n",
      "我 PRON\n",
      "到 VERB\n",
      "學校 VERB\n",
      "。 PUNCT\n",
      "然後 ADV\n",
      "， PUNCT\n",
      "她 PRON\n",
      "就 ADV\n",
      "去 VERB\n",
      "運 VERB\n",
      "動場 NOUN\n",
      "跑步 VERB\n",
      "。 PUNCT\n",
      "放學 VERB\n",
      "後 PART\n",
      "， PUNCT\n",
      "當 VERB\n",
      "我 PRON\n",
      "做 VERB\n",
      "功課時 NOUN\n",
      "， PUNCT\n",
      "有 VERB\n",
      "不 ADV\n",
      "明白 VERB\n",
      "的 PART\n",
      "地方 NOUN\n",
      "， PUNCT\n",
      "媽媽 NOUN\n",
      "便 ADV\n",
      "像 ADP\n",
      "老師 NOUN\n",
      "一 NUM\n",
      "樣 NUM\n",
      "， PUNCT\n",
      "坐到 VERB\n",
      "我 PRON\n",
      "身邊 NOUN\n",
      "， PUNCT\n",
      "循循善誘 ADV\n",
      "地 PART\n",
      "指導 VERB\n",
      "我 PRON\n",
      "， PUNCT\n",
      "令 VERB\n",
      "我 PRON\n",
      "茅塞 ADV\n",
      "頓開 VERB\n",
      "。 PUNCT\n"
     ]
    }
   ],
   "source": [
    "#SPACY\n",
    "nlp = zh_core_web_sm.load()\n",
    "    \n",
    "doc = nlp(u'每天早上，媽媽都會為我準備早餐，並且送我到學校。然後，她就去運動場跑步。放學後，當我做功課時，有不明白的地方，媽媽便像老師一樣，坐到我身邊，循循善誘地指導我，令我茅塞頓開。')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['每天', 'N-nc'], ['早上', 'N-nc'], ['，', 'M-c'], ['媽媽', 'N-nc'], ['都會', 'N-nc'], ['為我', 'N-nc'], ['準備', 'N-nc'], ['早餐', 'A-c'], ['，', 'M-c'], ['並且', 'N-nc'], ['送我', 'N-nc'], ['到', 'N-nc'], ['學校', 'N-nc'], ['。', 'M-p'], ['然後', 'N-nc'], ['，', 'M-c'], ['她', 'N-nc'], ['就去', 'N-nc'], ['運動', 'N-nc'], ['場跑', 'N-nc'], ['步', 'Q-n'], ['。', 'M-p'], ['放學', 'N-nc'], ['後', 'Q-n'], ['，', 'M-c'], ['當我', 'N-nc'], ['做功', 'N-nc'], ['課時', 'N-nc'], ['，', 'M-c'], ['有不', 'N-pn'], ['明白', 'N-nc'], ['的', 'Q-j'], ['地方', 'N-nc'], ['，', 'M-c'], ['媽媽', 'N-nc'], ['便像', 'N-nc'], ['老師', 'N-nc'], ['一樣', 'N-pn'], ['，', 'M-c'], ['坐', 'N-nc'], ['到我', 'N-nc'], ['身邊', 'N-nc'], ['，', 'M-c'], ['循循善', 'N-nc'], ['誘地', 'N-nc'], ['指導', 'N-nc'], ['我', 'Q-n'], ['，', 'M-c'], ['令我', 'N-nc'], ['茅塞', 'N-nc'], ['頓開', 'N-nc'], ['。', 'M-p']]\n"
     ]
    }
   ],
   "source": [
    "from rakutenma import RakutenMA\n",
    "rma = RakutenMA()\n",
    "# Initialize a RakutenMA instance with a pre-trained model\n",
    "rma = RakutenMA(phi=1024, c=0.007812)  # Specify hyperparameter for SCW (for demonstration purpose)\n",
    "rma.load(\"model_ja.json\")\n",
    "\n",
    "# Set the feature hash function (15bit)\n",
    "rma.hash_func = rma.create_hash_func(15)\n",
    "\n",
    "# Tokenize one sample sentence\n",
    "print(rma.tokenize('每天早上，媽媽都會為我準備早餐，並且送我到學校。然後，她就去運動場跑步。放學後，當我做功課時，有不明白的地方，媽媽便像老師一樣，坐到我身邊，循循善誘地指導我，令我茅塞頓開。'));\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n",
      "每天_r 早上_t ，_w 媽媽_n 都_d 會為_v 我_r 準備_v 早餐_n ，_w 並且_c 送_v 我_r 到_v 學校_n 。_w 然後_a ，_w 她_r 就_d 去_v 運動場_n 跑步_v 。_w 放_v 學後_n ，_w 當_v 我_r 做_v 功課時_id ，_w 有_v 不_d 明白_a 的_u 地方_n ，_w 媽媽_n 便_d 像_v 老師一樣_id ，_w 坐_v 到_v 我_r 身_g 邊_v ，_w 循循善誘_id 地_u 指導_v 我_r ，_w 令_v 我_r 茅塞頓開_id 。_w\n"
     ]
    }
   ],
   "source": [
    "import thulac   \n",
    "\n",
    "thu1 = thulac.thulac()  #默认模式\n",
    "text = thu1.cut('每天早上，媽媽都會為我準備早餐，並且送我到學校。然後，她就去運動場跑步。放學後，當我做功課時，有不明白的地方，媽媽便像老師一樣，坐到我身邊，循循善誘地指導我，令我茅塞頓開。', text=True)  #进行一句话分词\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('每天', 'pronoun'),\n",
       " ('早上', 'time word'),\n",
       " ('，', 'punctuation mark'),\n",
       " ('媽', 'noun'),\n",
       " ('媽', 'noun'),\n",
       " ('都', 'adverb'),\n",
       " ('會', 'noun'),\n",
       " ('為', 'noun'),\n",
       " ('我', 'pronoun'),\n",
       " ('準', 'noun'),\n",
       " ('備', 'noun'),\n",
       " ('早餐', 'noun'),\n",
       " ('，', 'punctuation mark'),\n",
       " ('並', 'noun'),\n",
       " ('且', 'conjunction'),\n",
       " ('送', 'verb'),\n",
       " ('我', 'pronoun'),\n",
       " ('到', 'verb'),\n",
       " ('學', 'noun'),\n",
       " ('校', 'noun'),\n",
       " ('。', 'punctuation mark'),\n",
       " ('然', 'pronoun'),\n",
       " ('後', 'noun'),\n",
       " ('，', 'punctuation mark'),\n",
       " ('她', 'pronoun'),\n",
       " ('就', 'adverb'),\n",
       " ('去', 'verb'),\n",
       " ('運', 'noun'),\n",
       " ('動', 'noun'),\n",
       " ('場', 'noun'),\n",
       " ('跑步', 'verb'),\n",
       " ('。', 'punctuation mark'),\n",
       " ('放', 'verb'),\n",
       " ('學', 'noun'),\n",
       " ('後', 'noun'),\n",
       " ('，', 'punctuation mark'),\n",
       " ('當', 'noun'),\n",
       " ('我', 'pronoun'),\n",
       " ('做功', 'noun'),\n",
       " ('課', 'noun'),\n",
       " ('時', 'noun'),\n",
       " ('，', 'punctuation mark'),\n",
       " ('有', 'verb'),\n",
       " ('不', 'adverb'),\n",
       " ('明白', 'adjective'),\n",
       " ('的', 'particle'),\n",
       " ('地方', 'noun'),\n",
       " ('，', 'punctuation mark'),\n",
       " ('媽', 'noun'),\n",
       " ('媽', 'noun'),\n",
       " ('便', 'adverb'),\n",
       " ('像', 'verb'),\n",
       " ('老', 'adjective'),\n",
       " ('師', 'noun'),\n",
       " ('一', 'numeral'),\n",
       " ('樣', 'noun'),\n",
       " ('，', 'punctuation mark'),\n",
       " ('坐', 'verb'),\n",
       " ('到', 'verb'),\n",
       " ('我', 'pronoun'),\n",
       " ('身', 'noun'),\n",
       " ('邊', 'noun'),\n",
       " ('，', 'punctuation mark'),\n",
       " ('循', 'verb'),\n",
       " ('循', 'verb'),\n",
       " ('善', 'adjective'),\n",
       " ('誘', 'noun'),\n",
       " ('地', 'particle'),\n",
       " ('指', 'verb'),\n",
       " ('導', 'noun'),\n",
       " ('我', 'pronoun'),\n",
       " ('，', 'punctuation mark'),\n",
       " ('令', 'verb'),\n",
       " ('我', 'pronoun'),\n",
       " ('茅', 'noun'),\n",
       " ('塞', 'distinguishing word'),\n",
       " ('頓', 'noun'),\n",
       " ('開', 'noun'),\n",
       " ('。', 'punctuation mark')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pynlpir\n",
    "pynlpir.open()\n",
    "\n",
    "s = '每天早上，媽媽都會為我準備早餐，並且送我到學校。然後，她就去運動場跑步。放學後，當我做功課時，有不明白的地方，媽媽便像老師一樣，坐到我身邊，循循善誘地指導我，令我茅塞頓開。'\n",
    "pynlpir.segment(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
